
@article{russell_labelme_2008,
	title = {{LabelMe}: {A} {Database} and {Web}-{Based} {Tool} for {Image} {Annotation}},
	volume = {77},
	issn = {0920-5691, 1573-1405},
	shorttitle = {{LabelMe}},
	url = {http://link.springer.com/10.1007/s11263-007-0090-8},
	doi = {10.1007/s11263-007-0090-8},
	abstract = {We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative ???The ???rst two authors contributed equally to this work.},
	language = {en},
	number = {1-3},
	urldate = {2019-01-21},
	journal = {International Journal of Computer Vision},
	author = {Russell, Bryan C. and Torralba, Antonio and Murphy, Kevin P. and Freeman, William T.},
	month = may,
	year = {2008},
	note = {02464},
	pages = {157--173},
	file = {Russell et al. - 2008 - LabelMe A Database and Web-Based Tool for Image A.pdf:/home/srvander/Zotero/storage/7QT8PSBE/Russell et al. - 2008 - LabelMe A Database and Web-Based Tool for Image A.pdf:application/pdf}
}

@misc{tensorflow2015-whitepaper,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
Abadi, Mart\'{\i}n and
Agarwal, Ashish and
Barham, Paul and
Brevdo, Eugene and
Chen, Zhifeng and
Citro, Craig and
Corrado, Greg~S. and
Davis, Andy and
Dean, Jeffrey and
Devin, Matthieu and
Ghemawat, Sanjay and
Goodfellow, Ian and
Harp, Andrew and
Irving, Geoffrey and
Isard, Michael and
Jia, Yangqing and
Jozefowicz, Rafal and
Kaiser, Lukasz and
Kudlur, Manjunath and
Levenberg, Josh and
Man\'{e}, Dan and
Monga, Rajat and
Moore, Sherry and
Murray, Derek and
Olah, Chris and
Schuster, Mike and
Shlens, Jonathon and
Steiner, Benoit and
Sutskever, Ilya and
Talwar, Kunal and
Tucker, Paul and
Vanhoucke, Vincent and
Vasudevan, Vijay and
Vi\'{e}gas, Fernanda and
Vinyals, Oriol and
Warden, Pete and
Wattenberg, Martin and
Wicke, Martin and
Yu, Yuan and
Zheng, Xiaoqiang},
  year={2015},
}

@article{gross_variability_2013,
	title = {The variability and significance of class characteristics in footwear impressions},
	volume = {63},
	number = {3},
	journal = {Journal of Forensic Identification},
	author = {Gross, Susan and Jeppesen, Dane and Neumann, Cedric},
	year = {2013},
	pages = {332}
}

@article{hamm_individuality_1989,
	title = {The individuality of class characteristics in {Converse} {All}-{Star} footwear},
	volume = {39},
	number = {5},
	journal = {Journal of Forensic Identification},
	author = {Hamm, Ernest D},
	year = {1989},
	pages = {277--292}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}

@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2019-01-18},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014}
}

@article{luostarinen_measuring_2014,
	title = {Measuring the accuracy of automatic shoeprint recognition methods},
	volume = {59},
	number = {6},
	journal = {Journal of forensic sciences},
	author = {Luostarinen, Tapio and Lehmussola, Antti},
	year = {2014},
	pages = {1627--1634}
}

@article{benedict_geographical_2014,
	title = {Geographical variation of shoeprint comparison class correspondences},
	volume = {54},
	number = {5},
	journal = {Science and Justice},
	author = {Benedict, Indrika and Corke, Elisabeth and Morgan-Smith, Rian and Maynard, Philip and Curran, James M and Buckleton, John and Roux, Claude},
	year = {2014},
	pages = {335--337}
}

@inproceedings{pavlou_automatic_2006,
	title = {Automatic extraction and classification of footwear patterns},
	booktitle = {International {Conference} on {Intelligent} {Data} {Engineering} and {Automated} {Learning}},
	publisher = {Springer},
	author = {Pavlou, Maria and Allinson, Nigel M},
	editor = {Corchado, E and Yin, H and Botti, V and Fyfe, C},
	year = {2006},
	pages = {721--728}
}

@inproceedings{zhang_automatic_2005,
	title = {Automatic shoeprint retrieval system for use in forensic investigations},
	volume = {99},
	booktitle = {{UK} {Workshop} {On} {Computational} {Intelligence}},
	author = {Zhang, Lin and Allinson, Nigel},
	editor = {Mirkin, Boris and Magoulas, George},
	year = {2005}
}


@book{chollet_deep_2018,
	title = {Deep {Learning} with {R}},
	publisher = {Manning Publications Company},
	author = {Chollet, Francois and Allaire, Joseph J},
	year = {2018}
}

@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {https://arxiv.org/abs/1409.1556},
	language = {en},
	urldate = {2018-10-16},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014}
}

@article{shridhar_bayesian_2018,
	title = {Bayesian {Convolutional} {Neural} {Networks} with {Variational} {Inference}},
	url = {http://arxiv.org/abs/1806.05978},
	urldate = {2019-01-17},
	journal = {arXiv:1806.05978 [cs, stat]},
	author = {Shridhar, Kumar and Laumann, Felix and Maurin, Adrian Llopart and Olsen, Martin and Liwicki, Marcus},
	month = jun,
	year = {2018}
}

@article{simonyan_deep_2013,
	title = {Deep inside convolutional networks: {Visualising} image classification models and saliency maps},
	journal = {arXiv preprint arXiv:1312.6034},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	year = {2013},
	note = {01202 
Citation Key: simonyan2013deep}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2018-11-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}

@article{hancockInterpretationShoeprintComparison2012,
  title = {The Interpretation of Shoeprint Comparison Class Correspondences},
  volume = {52},
  number = {4},
  journal = {Science and Justice},
  year = {2012},
  pages = {243--248},
  author = {Hancock, Sheida and Morgan-Smith, Rian and Buckleton, John}
}